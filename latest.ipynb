{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final distribution: Confidence_2class\n",
      "3    0.516029\n",
      "2    0.483971\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training set distribution:\n",
      " Confidence_2class\n",
      "3    0.516556\n",
      "2    0.483444\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set distribution:\n",
      " Confidence_2class\n",
      "3    0.514801\n",
      "2    0.485199\n",
      "Name: proportion, dtype: float64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654929\n",
      "         Iterations: 37\n",
      "         Function evaluations: 39\n",
      "         Gradient evaluations: 39\n",
      "\n",
      "Model Summary:\n",
      "                             OrderedModel Results                             \n",
      "==============================================================================\n",
      "Dep. Variable:      Confidence_2class   Log-Likelihood:                -1186.7\n",
      "Model:                   OrderedModel   AIC:                             2389.\n",
      "Method:            Maximum Likelihood   BIC:                             2433.\n",
      "Date:                Tue, 28 Jan 2025                                         \n",
      "Time:                        09:09:10                                         \n",
      "No. Observations:                1812                                         \n",
      "Df Residuals:                    1804                                         \n",
      "Df Model:                           7                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Age                          -1.8062      0.241     -7.482      0.000      -2.279      -1.333\n",
      "Sex                           0.1262      0.103      1.231      0.218      -0.075       0.327\n",
      "Scale of incomes             -0.1317      0.027     -4.936      0.000      -0.184      -0.079\n",
      "Strong Leader                 0.2229      0.055      4.061      0.000       0.115       0.330\n",
      "Expert Non Govt Person       -0.1303      0.061     -2.139      0.032      -0.250      -0.011\n",
      "Highest educational level    -0.0581      0.035     -1.677      0.093      -0.126       0.010\n",
      "Importance of democracy      -0.2434      0.229     -1.063      0.288      -0.692       0.206\n",
      "2/3                          -1.4802      0.250     -5.928      0.000      -1.970      -0.991\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ordinal regression from statsmodels\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "\n",
    "# For train/test split and data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Load Data\n",
    "# -----------------------------------------------------------------------------\n",
    "wave7_csv = \"data/preprocessed/filtered_wave_7.csv\"\n",
    "df = pd.read_csv(wave7_csv, low_memory=True)\n",
    "\n",
    "# 2) Filter for USA\n",
    "df_usa = df[df[\"Country\"] == 840].copy()\n",
    "\n",
    "# 3) Replace coded missing values with NaN\n",
    "missing_values = [-1, -2, -4, -5]\n",
    "df_usa.replace(missing_values, np.nan, inplace=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) List \"C\" columns to aggregate\n",
    "#    Adjust this to match your dataset\n",
    "# -----------------------------------------------------------------------------\n",
    "confidence_cols = [\n",
    "    \"C Government\", \n",
    "    \"C Political parties\", \n",
    "    \"C Courts\", \n",
    "    \"C Elections\", \n",
    "    \"C Television\",\n",
    "    \"C Police\",\n",
    "    \"C Armed forces\", \n",
    "    \"C Civil services\"\n",
    "]\n",
    "\n",
    "# 5) Create an aggregated measure: \"Overall_Confidence\"\n",
    "df_usa[\"Overall_Confidence\"] = df_usa[confidence_cols].mean(axis=1)\n",
    "\n",
    "# 6) Convert to ordinal (1–4) by rounding\n",
    "df_usa[\"Overall_Confidence_Ordinal\"] = df_usa[\"Overall_Confidence\"].round()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7) Merge Rare Classes (1→2, 4→3) => 2-Class Problem\n",
    "#    After merging, you end up with categories {2, 3}.\n",
    "#    Class 2 now represents original (1 or 2), Class 3 represents original (3 or 4).\n",
    "# -----------------------------------------------------------------------------\n",
    "df_usa[\"Confidence_2class\"] = df_usa[\"Overall_Confidence_Ordinal\"].replace({1: 2, 4: 3})\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8) Choose Additional Predictors (EXCLUDING original \"C\" columns to avoid leakage)\n",
    "# -----------------------------------------------------------------------------\n",
    "predictor_cols = [\n",
    "    \"Age\",\n",
    "    \"Sex\",\n",
    "    \"Scale of incomes\",\n",
    "    \"Strong Leader\",\n",
    "    \"Expert Non Govt Person\",\n",
    "    \"Highest educational level\",\n",
    "    \"Importance of democracy\",\n",
    "    # ... Add or remove columns as desired\n",
    "]\n",
    "\n",
    "df_model = df_usa[predictor_cols + [\"Confidence_2class\"]].copy()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9) Handle Missing Values\n",
    "#    - Categorical => fill with mode\n",
    "#    - Numeric => fill with median\n",
    "# -----------------------------------------------------------------------------\n",
    "# Identify categorical vs numeric\n",
    "categorical_cols = [\"Sex\", \"Scale of incomes\", \"Strong Leader\", \n",
    "                    \"Expert Non Govt Person\", \"Highest educational level\"]\n",
    "numeric_cols = [\"Age\", \"Importance of democracy\"]\n",
    "\n",
    "# Impute categorical\n",
    "for col in categorical_cols:\n",
    "    mode_val = df_model[col].mode(dropna=True)\n",
    "    if not mode_val.empty:\n",
    "        df_model[col] = df_model[col].fillna(mode_val[0])\n",
    "\n",
    "# Impute numeric\n",
    "for col in numeric_cols:\n",
    "    median_val = df_model[col].median()\n",
    "    df_model[col] = df_model[col].fillna(median_val)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 10) Encode Categorical Variables\n",
    "# -----------------------------------------------------------------------------\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df_model[col] = encoder.fit_transform(df_model[col].astype(str))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 11) Scale Continuous Variables\n",
    "# -----------------------------------------------------------------------------\n",
    "scaler = MinMaxScaler()\n",
    "df_model[\"Age\"] = df_model[\"Age\"].astype(float)\n",
    "df_model[\"Importance of democracy\"] = df_model[\"Importance of democracy\"].astype(float)\n",
    "\n",
    "df_model[\"Age\"] = scaler.fit_transform(df_model[[\"Age\"]])\n",
    "df_model[\"Importance of democracy\"] = scaler.fit_transform(df_model[[\"Importance of democracy\"]])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 12) Drop rows where the target is missing\n",
    "# -----------------------------------------------------------------------------\n",
    "df_model.dropna(subset=[\"Confidence_2class\"], inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "df_model[\"Confidence_2class\"] = df_model[\"Confidence_2class\"].astype(int)\n",
    "\n",
    "# Check final class distribution\n",
    "print(\"Final distribution:\", df_model[\"Confidence_2class\"].value_counts(normalize=True))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 13) Define X, y and Train/Test Split\n",
    "# -----------------------------------------------------------------------------\n",
    "X = df_model.drop(\"Confidence_2class\", axis=1)\n",
    "y = df_model[\"Confidence_2class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTraining set distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\nTest set distribution:\\n\", y_test.value_counts(normalize=True))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 14) Ordinal Model with 2 Classes\n",
    "#     (Effectively logistic regression if you only have two classes.)\n",
    "# -----------------------------------------------------------------------------\n",
    "ord_model = OrderedModel(\n",
    "    endog=y_train,\n",
    "    exog=X_train,\n",
    "    distr='logit'\n",
    ")\n",
    "\n",
    "results = ord_model.fit(method='bfgs', maxiter=100)\n",
    "print(\"\\nModel Summary:\")\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[211 166]\n",
      " [130 270]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.62      0.56      0.59       377\n",
      "           3       0.62      0.68      0.65       400\n",
      "\n",
      "    accuracy                           0.62       777\n",
      "   macro avg       0.62      0.62      0.62       777\n",
      "weighted avg       0.62      0.62      0.62       777\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.6190476190476191\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 15) Predict on Test Set\n",
    "# -----------------------------------------------------------------------------\n",
    "pred_probs = results.predict(exog=X_test, which=\"prob\")  # shape: (n_samples, 2) \n",
    "pred_probs_array = pred_probs.to_numpy()\n",
    "\n",
    "# We now have 2 classes, let's see what they are\n",
    "unique_classes = sorted(y_train.unique())  # e.g., [2, 3]\n",
    "argmax_indices = pred_probs_array.argmax(axis=1)\n",
    "\n",
    "y_pred = [unique_classes[idx] for idx in argmax_indices]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 16) Evaluate\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variance Inflation Factor (VIF):\n",
      "                     Feature       VIF\n",
      "0                        Age  3.303106\n",
      "1                        Sex  1.612737\n",
      "2           Scale of incomes  6.684654\n",
      "3              Strong Leader  5.572863\n",
      "4     Expert Non Govt Person  4.524944\n",
      "5  Highest educational level  6.973350\n",
      "Error for threshold 2: shapes (2589,5) and (0,) not aligned: 5 (dim 1) != 0 (dim 0)\n",
      "\n",
      "Proportional Odds Test could not be completed due to errors.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656222\n",
      "         Iterations: 27\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "\n",
      "Model Summary:\n",
      "                             OrderedModel Results                             \n",
      "==============================================================================\n",
      "Dep. Variable:      Confidence_2class   Log-Likelihood:                -1189.1\n",
      "Model:                   OrderedModel   AIC:                             2390.\n",
      "Method:            Maximum Likelihood   BIC:                             2423.\n",
      "Date:                Tue, 28 Jan 2025                                         \n",
      "Time:                        09:12:19                                         \n",
      "No. Observations:                1812                                         \n",
      "Df Residuals:                    1806                                         \n",
      "Df Model:                           5                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "Age                       -1.8237      0.231     -7.884      0.000      -2.277      -1.370\n",
      "Sex                        0.1668      0.101      1.656      0.098      -0.031       0.364\n",
      "Scale of incomes          -0.1466      0.026     -5.717      0.000      -0.197      -0.096\n",
      "Strong Leader              0.1928      0.053      3.644      0.000       0.089       0.296\n",
      "Expert Non Govt Person    -0.1273      0.061     -2.094      0.036      -0.247      -0.008\n",
      "2/3                       -1.1714      0.193     -6.058      0.000      -1.550      -0.792\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import chi2\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Load and Preprocess Data\n",
    "# -----------------------------------------------------------------------------\n",
    "wave7_csv = \"data/preprocessed/filtered_wave_7.csv\"\n",
    "df = pd.read_csv(wave7_csv, low_memory=True)\n",
    "\n",
    "# Filter for USA and replace missing values\n",
    "df_usa = df[df[\"Country\"] == 840].copy()\n",
    "df_usa.replace([-1, -2, -4, -5], np.nan, inplace=True)\n",
    "\n",
    "# Define Confidence Columns\n",
    "confidence_cols = [\n",
    "    \"C Government\", \n",
    "    \"C Political parties\", \n",
    "    \"C Courts\", \n",
    "    \"C Elections\", \n",
    "    \"C Television\",\n",
    "    \"C Police\",\n",
    "    \"C Armed forces\", \n",
    "    \"C Civil services\"\n",
    "]\n",
    "df_usa[\"Overall_Confidence\"] = df_usa[confidence_cols].mean(axis=1)\n",
    "df_usa[\"Overall_Confidence_Ordinal\"] = df_usa[\"Overall_Confidence\"].round()\n",
    "df_usa[\"Confidence_2class\"] = df_usa[\"Overall_Confidence_Ordinal\"].replace({1: 2, 4: 3})\n",
    "\n",
    "# Predictors\n",
    "predictor_cols = [\n",
    "    \"Age\",\n",
    "    \"Sex\",\n",
    "    \"Scale of incomes\",\n",
    "    \"Strong Leader\",\n",
    "    \"Expert Non Govt Person\",\n",
    "    \"Highest educational level\"\n",
    "]\n",
    "\n",
    "df_model = df_usa[predictor_cols + [\"Confidence_2class\"]].copy()\n",
    "\n",
    "# Impute Missing Values\n",
    "categorical_cols = [\"Sex\", \"Scale of incomes\", \"Strong Leader\", \"Expert Non Govt Person\", \"Highest educational level\"]\n",
    "numeric_cols = [\"Age\"]\n",
    "\n",
    "# Impute categorical with mode\n",
    "for col in categorical_cols:\n",
    "    mode_val = df_model[col].mode(dropna=True)\n",
    "    if not mode_val.empty:\n",
    "        df_model[col] = df_model[col].fillna(mode_val[0])\n",
    "\n",
    "# Impute numeric with median\n",
    "for col in numeric_cols:\n",
    "    median_val = df_model[col].median()\n",
    "    df_model[col] = df_model[col].fillna(median_val)\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df_model[col] = encoder.fit_transform(df_model[col].astype(str))\n",
    "\n",
    "# Scale continuous variables\n",
    "scaler = MinMaxScaler()\n",
    "df_model[\"Age\"] = scaler.fit_transform(df_model[[\"Age\"]])\n",
    "\n",
    "# Drop missing target values\n",
    "df_model.dropna(subset=[\"Confidence_2class\"], inplace=True)\n",
    "df_model[\"Confidence_2class\"] = df_model[\"Confidence_2class\"].astype(int)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Multicollinearity Check\n",
    "# -----------------------------------------------------------------------------\n",
    "X_vif = df_model.drop(\"Confidence_2class\", axis=1)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_vif.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "print(\"\\nVariance Inflation Factor (VIF):\")\n",
    "print(vif_data)\n",
    "\n",
    "# Drop \"Highest educational level\" if VIF > 6.5\n",
    "if \"Highest educational level\" in vif_data[vif_data[\"VIF\"] > 6.5][\"Feature\"].values:\n",
    "    df_model.drop(columns=[\"Highest educational level\"], inplace=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Proportional Odds Test\n",
    "# -----------------------------------------------------------------------------\n",
    "X = df_model.drop(\"Confidence_2class\", axis=1)\n",
    "y = df_model[\"Confidence_2class\"]\n",
    "\n",
    "log_likelihoods = []\n",
    "cutoffs = [2, 3]\n",
    "\n",
    "for threshold in cutoffs:\n",
    "    y_binary = (y >= threshold).astype(int)\n",
    "    try:\n",
    "        model = OrderedModel(y_binary, X, distr=\"logit\").fit(method=\"bfgs\", maxiter=100, disp=False)\n",
    "        log_likelihoods.append(model.llf)\n",
    "    except Exception as e:\n",
    "        print(f\"Error for threshold {threshold}: {e}\")\n",
    "        log_likelihoods.append(None)\n",
    "\n",
    "# Ensure log-likelihoods are valid for comparison\n",
    "if None not in log_likelihoods:\n",
    "    chi2_stat = 2 * (log_likelihoods[1] - log_likelihoods[0])\n",
    "    p_value = chi2.sf(chi2_stat, df=X.shape[1])\n",
    "    print(\"\\nProportional Odds Test:\")\n",
    "    print(f\"Chi-Square Statistic: {chi2_stat:.2f}, p-value: {p_value:.4f}\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(\"Proportional odds assumption violated.\")\n",
    "    else:\n",
    "        print(\"Proportional odds assumption holds.\")\n",
    "else:\n",
    "    print(\"\\nProportional Odds Test could not be completed due to errors.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Train/Test Split and Model Training\n",
    "# -----------------------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "ord_model = OrderedModel(y_train, X_train, distr=\"logit\")\n",
    "results = ord_model.fit(method=\"bfgs\", maxiter=100)\n",
    "print(\"\\nModel Summary:\")\n",
    "print(results.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WVS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
